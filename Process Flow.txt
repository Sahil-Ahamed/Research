Virtual Box 7.0.14
Win10_22H2_English_x64v1.iso

Windows 10 Pro
Version 22H2
OS Build 19045.2965
Experience Windows Feature Experience Pack 1000.19041.1000.0
64-bit operating system, x64-based processor
	2048GB Base Memory
	2 Processors
	30.00GB Virtual Storage
	10.77GB Actual Storage
	Bridge Adapter Network (During benign memory dump collection)
	Intel(R) Core(TM) i5-1035G1 CPU @ 1.00GHz 1.19GHz

Downloaded Comae-Toolkit-v20230117
Installed VirtualBox Guest Additions
Snapshot Taken (Base)

1. (Benign)
Runned powershell commands (For the memory dump of powershell.exe)
Runned DumpIt
Chenged Drag and Drop from Guest to Host
Collected Memory Dump from VM to Host
Renamed with program name
VM Shut Down
Machine restored to Base Snapshot

2. (Malicious)
Same machine configuration
Disabled Windows Defender Antivirus (Software + Group Policies/Registry Editor)
Disabled Windows Defender Firewall (Group Policies) + Turned off all security notifications.
Set execution policy bypass (Set-ExecutionPolicy -ExecutionPolicy Bypass -Scope Process)
Created Base 2 Snapshot
Connected Host to phone's hotspot. (Not to spread it to hostel WiFi)
Downloaded malware (Emotet an .exe file)
Installed 7zip
VM restarted to clear memory
Executed malware
Captured Memory dump
Drag and Drop Memory Dump to Host
VM restored to Base Snapshot 

3. Image generation
Transferred .dmp to Mac Mini (18GB RAM)
Modified binary2image.py script
Original GitHub repo:- https://github.com/ncarkaci/binary-to-image/blob/master/binary2image.py
Modified Code-----

import os
import math
import argparse
from PIL import Image
import numpy as np

def getBinaryData(filename):
    """
    Extract byte values from binary file and return as a list of integers.
    :param filename: .dmp file name
    :return: list of byte values
    """
    binary_values = []
    with open(filename, 'rb') as fileobject:
        data = fileobject.read(1)
        while data != b'':
            binary_values.append(ord(data))
            data = fileobject.read(1)
    return binary_values


def createGrayscaleImage(filename, size, output_dir):
    """
    Create a grayscale image from the binary data and save it in the desired output directory.
    :param filename: .dmp file name
    :param size: Size of the image (width, height)
    :param output_dir: Directory where images will be saved
    """
    grayscale_data = getBinaryData(filename)
    
    # Normalize grayscale data to the range 0-255
    grayscale_data = np.array(grayscale_data, dtype=np.uint8)
    grayscale_data = np.clip(grayscale_data, 0, 255)  # Ensure values are in range 0-255
    
    # Adjust data to the image size (width * height)
    if len(grayscale_data) < size[0] * size[1]:
        grayscale_data = np.pad(grayscale_data, (0, size[0] * size[1] - len(grayscale_data)), 'constant')
    else:
        grayscale_data = grayscale_data[:size[0] * size[1]]
    
    # Create image
    image = Image.new('L', size)
    image.putdata(grayscale_data)
    
    # Save the image
    image_name = os.path.basename(filename).replace('.dmp', f'_{size[0]}x{size[1]}.png')
    save_path = os.path.join(output_dir, image_name)
    
    image.save(save_path)
    print(f'Image saved at: {save_path}')


def process_file(file_path, output_dir):
    """
    Process a single file and generate two grayscale images (112x112 and 56x56).
    :param file_path: Path to the .dmp file
    :param output_dir: Output directory for saving images
    """
    print(f"Processing file: {file_path}")
    
    # Create 112x112 image
    createGrayscaleImage(file_path, (112, 112), output_dir)
    
    # Create 56x56 image
    createGrayscaleImage(file_path, (56, 56), output_dir)
    
    print(f"Completed processing of file: {file_path}")


def main(input_dir):
    """
    Main function to process all .dmp files in the directory.
    :param input_dir: Directory containing .dmp files (either Benign or Malicious)
    """
    if not os.path.isdir(input_dir):
        print(f"Invalid directory: {input_dir}")
        return

    # Determine output directory based on input directory (Benign or Malicious)
    base_dir = os.path.basename(input_dir)
    output_dir = os.path.join(os.path.dirname(input_dir), '..', 'Images', base_dir)

    if not os.path.exists(output_dir):
        os.makedirs(output_dir)

    print(f"Saving images to: {output_dir}")
    
    # Process all .dmp files in the directory
    for filename in os.listdir(input_dir):
        file_path = os.path.join(input_dir, filename)
        if filename.endswith('.dmp'):
            process_file(file_path, output_dir)
        else:
            print(f"Skipping non-.dmp file: {filename}")

    print("TASK COMPLETED SUCCESSFULLY")


if __name__ == '__main__':
    # Parse arguments
    parser = argparse.ArgumentParser(prog='binary_to_image.py', description="Convert .dmp binary file to images")
    parser.add_argument('input_dir', help="Directory containing .dmp files (Benign or Malicious)")

    args = parser.parse_args()

    # Run the main function with the provided directory
    main(args.input_dir)

Image details:
	1. Single channel grayscale images
	2. Size of 56x56 & 112x112
	3. 0-255 normalized value
Collected images



4. Feature Extraction
 (a) Used modified version of AGCWD instead of CLAHE.
     Original code GitHub Repo:- https://github.com/qyou/AGCWD/blob/master/agcwd.py
     Used AI to find the best entropy to finetune the image by tweaking the values of AGCWD.
     Entropy after AGCWD (single specific image, not same for every image):- 2.9984

Modified Code--

import numpy as np
import cv2
import os

def agcwd(image, w=0.5):
    is_colorful = len(image.shape) >= 3
    img = extract_value_channel(image) if is_colorful else image
    img_pdf = get_pdf(img)
    max_intensity = np.max(img_pdf)
    min_intensity = np.min(img_pdf)

    # Apply weighting distribution
    w_img_pdf = max_intensity * (((img_pdf - min_intensity) / (max_intensity - min_intensity)) ** w)
    w_img_cdf = np.cumsum(w_img_pdf) / np.sum(w_img_pdf)

    # Intensity transformation
    l_intensity = np.arange(0, 256)
    l_intensity = np.array([255 * (e / 255) ** (1 - w_img_cdf[e]) for e in l_intensity], dtype=np.uint8)

    # Enhance the image
    enhanced_image = np.copy(img)
    height, width = img.shape
    for i in range(height):
        for j in range(width):
            intensity = enhanced_image[i, j]
            enhanced_image[i, j] = l_intensity[intensity]

    # Clip pixel intensities to [0.1, 0.9] and rescale to [0, 255]
    enhanced_image = np.clip(enhanced_image / 255.0, 0.1, 0.9)
    enhanced_image = (enhanced_image * 255).astype(np.uint8)

    # Reapply value channel if the image is colorful
    enhanced_image = set_value_channel(image, enhanced_image) if is_colorful else enhanced_image
    return enhanced_image

def extract_value_channel(color_image):
    color_image = color_image.astype(np.float32) / 255.
    hsv = cv2.cvtColor(color_image, cv2.COLOR_BGR2HSV)
    v = hsv[:, :, 2]
    return np.uint8(v * 255)

def get_pdf(gray_image):
    height, width = gray_image.shape
    pixel_count = height * width
    hist = cv2.calcHist([gray_image], [0], None, [256], [0, 256])
    return hist / pixel_count

def set_value_channel(color_image, value_channel):
    value_channel = value_channel.astype(np.float32) / 255
    color_image = color_image.astype(np.float32) / 255.
    color_image = cv2.cvtColor(color_image, cv2.COLOR_BGR2HSV)
    color_image[:, :, 2] = value_channel
    color_image = np.array(cv2.cvtColor(color_image, cv2.COLOR_HSV2BGR) * 255, dtype=np.uint8)
    return color_image

def process_images(input_folder, output_folder, w=0.5):
    if not os.path.exists(output_folder):
        os.makedirs(output_folder)

    for file_name in os.listdir(input_folder):
        input_path = os.path.join(input_folder, file_name)
        if not os.path.isfile(input_path):
            continue

        image = cv2.imread(input_path)
        if image is None:
            print(f"Skipping invalid image: {input_path}")
            continue

        enhanced_image = agcwd(image, w)

        output_path = os.path.join(output_folder, os.path.splitext(file_name)[0] + '.png')
        cv2.imwrite(output_path, enhanced_image)
        print(f"Processed and saved: {output_path}")

def main():
    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument('input_folder', help='Path to the input image folder')
    parser.add_argument('output_folder', help='Path to the output image folder')
    args = parser.parse_args()

    process_images(args.input_folder, args.output_folder, w=0.5)

if __name__ == '__main__':
    main()


 (b) Used modified version of Guided Image Filtering(GIF) instead of Wavelet transform.
     Original code GitHub Repo:- https://github.com/lisabug/guided-filter
     Used AI to find the best entropy to finetune the image by tweaking.
     Entropy after GIF (single specific image, not every image):- 6.2424413

     cloned repo to system
     modified smooth.py for (from .pad)
     modified pad.py (xrange to range). python3 supports range

Modified Code--

import cv2
import numpy as np
import itertools
import os
import sys

from core.filter import GuidedFilter
from tools import visualize as vis
from cv.image import to_8U, to_32F

# Fixed parameters
RADIUS = 8
EPSILON = 0.32

def process_image(input_path, output_path):
    """Apply guided filter to an image and save as PNG."""
    image = cv2.imread(input_path, cv2.IMREAD_COLOR)
    if image is None:
        print(f"Error: Could not read {input_path}")
        return

    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    
    # Convert to grayscale for filtering
    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
    
    # Apply guided filter
    GF = GuidedFilter(gray, radius=RADIUS, eps=EPSILON)
    filtered = GF.filter(gray)
    
    # Convert back to BGR and save as PNG
    output_file = os.path.splitext(os.path.basename(input_path))[0] + ".png"
    output_full_path = os.path.join(output_path, output_file)
    cv2.imwrite(output_full_path, cv2.cvtColor(to_8U(filtered), cv2.COLOR_GRAY2BGR))
    print(f"Processed: {input_path} -> {output_full_path}")

def process_directory(input_dir, output_dir):
    """Process all image files in the input directory."""
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)

    for filename in os.listdir(input_dir):
        input_path = os.path.join(input_dir, filename)

        # Process only image files
        if filename.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp', '.tiff')):
            process_image(input_path, output_dir)

if __name__ == '__main__':
    if len(sys.argv) != 3:
        print("Usage: python3 GIF.py input/directory output/directory")
        sys.exit(1)

    input_dir = sys.argv[1]
    output_dir = sys.argv[2]

    process_directory(input_dir, output_dir)




  (c)Entropy checking Code:-

import cv2
import numpy as np

def calculate_entropy(image):
    """
    Calculate the entropy of a grayscale image using the pixel intensity histogram.

    Parameters:
        image (numpy array): Grayscale image as a 2D array.

    Returns:
        float: Entropy value.
    """
    # Compute histogram of pixel intensities
    hist, _ = np.histogram(image.ravel(), bins=256, range=(0, 256))
    
    # Normalize histogram to create a probability distribution
    hist = hist / hist.sum()
    
    # Calculate entropy using the formula: -Σ(p(x) * log2(p(x)))
    entropy_value = -np.sum(hist * np.log2(hist + 1e-10))  # Small value avoids log(0)
    
    return entropy_value


# Example Usage
if __name__ == "__main__":
    # Load the image
    image_path = 'image.png'  # Replace with your image path
    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)  # Load as grayscale
    
    # Calculate and print entropy
    entropy_value = calculate_entropy(image)
    print("Entropy of the image:", entropy_value)

  d) Rotated Every image into 8 possible directions to increase dataset. Ultimately having 640 images.

  e) Created two .csv (one of 56x56 other of 112x112):

.csv includes:
File name, Features, Label (0--> Benign, 1--> Malicious), Features normalized between 0-1 (255), No Null Values.
Python Code:-

import os
import cv2
import numpy as np
import pandas as pd
import argparse

def process_images(folder_path):
    # Two lists to store rows for each resolution.
    data_112 = []
    data_56 = []
    
    # Iterate over the subfolders: "Benign" and "Malicious"
    for label_name in ['Benign', 'Malicious']:
        # Assign label: 0 for benign, 1 for malicious
        label = 0 if label_name.lower() == 'benign' else 1
        subfolder = os.path.join(folder_path, label_name)
        
        # Process each image in the subfolder.
        for file_name in os.listdir(subfolder):
            if file_name.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tif', '.tiff')):
                file_path = os.path.join(subfolder, file_name)
                # Read the image in grayscale mode.
                img = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)
                if img is None:
                    print(f"Warning: Unable to read image {file_path}. Skipping.")
                    continue
                
                # Process based on image size.
                if img.shape == (112, 112):
                    # Normalize the pixel values to the range [0, 1].
                    img_norm = img.astype(np.float32) / 255.0
                    # Flatten the image into a 1D vector.
                    features = img_norm.flatten()
                    row = [file_name] + features.tolist() + [label]
                    data_112.append(row)
                elif img.shape == (56, 56):
                    img_norm = img.astype(np.float32) / 255.0
                    features = img_norm.flatten()
                    row = [file_name] + features.tolist() + [label]
                    data_56.append(row)
                else:
                    print(f"Skipping {file_path} due to unexpected size: {img.shape}")
                    
    return data_112, data_56

def save_to_csv(data, resolution, output_file):
    # Determine the number of features from the image resolution.
    if resolution == 112:
        num_features = 112 * 112
    elif resolution == 56:
        num_features = 56 * 56
    else:
        raise ValueError("Unsupported resolution")
        
    # Create column names: 'filename', then f0, f1, ..., f{num_features-1}, and 'label'
    columns = ['filename'] + [f"f{i}" for i in range(num_features)] + ['label']
    df = pd.DataFrame(data, columns=columns)
    # Remove any rows with null values (shouldn't happen, but just in case).
    df.dropna(inplace=True)
    # Save the DataFrame to CSV.
    df.to_csv(output_file, index=False)
    print(f"Saved {len(df)} rows to {output_file}")

if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='Convert images to CSV with normalized features.')
    parser.add_argument('--folder', type=str, required=True,
                        help='Path to the main folder containing "Benign" and "Malicious" subfolders.')
    args = parser.parse_args()
    folder_path = args.folder

    data_112, data_56 = process_images(folder_path)
    
    # Save two CSV files: one for 112x112 images and one for 56x56 images.
    save_to_csv(data_112, 112, 'features_112.csv')
    save_to_csv(data_56, 56, 'features_56.csv')

f) Used Jupyter and trained ML models on the datasets. The details of every model and how they are trained are saved within the model folders.